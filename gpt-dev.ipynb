{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef4d2009-3c89-48d2-93cc-c1fce0a94874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-16 06:33:52--  http://biblioteka.kijowski.pl/sienkiewicz%20henryk/quo%20vadis%20(ang).txt\n",
      "Resolving biblioteka.kijowski.pl (biblioteka.kijowski.pl)... 77.65.215.2\n",
      "Connecting to biblioteka.kijowski.pl (biblioteka.kijowski.pl)|77.65.215.2|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 642072 (627K) [text/plain]\n",
      "Saving to: ‘quo vadis (ang).txt’\n",
      "\n",
      "quo vadis (ang).txt 100%[===================>] 627,02K  1,59MB/s    in 0,4s    \n",
      "\n",
      "2024-05-16 06:33:53 (1,59 MB/s) - ‘quo vadis (ang).txt’ saved [642072/642072]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#based on \"Let's build GPT: from scratch, in code, spelled out.\" from Andrej Karpathy\n",
    "\n",
    "# download Quo Vadis from Henryk Sienkiewicz\n",
    "!wget \"http://biblioteka.kijowski.pl/sienkiewicz%20henryk/quo%20vadis%20(ang).txt\"\n",
    "!mv \"quo vadis (ang).txt\" quo_vadis.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb148ef1-f986-4f03-948d-da5afdf4ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get pointer to read text\n",
    "with open('quo_vadis.txt', encoding='latin-1') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b82c058-6795-4e9a-b00e-5f1474e93aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of text: 630169\n",
      "Project Gutenberg EBook, Quo Vadis, by Henryk Sienkiewicz\n",
      "\n",
      "Copyright laws are changing all over the world. Be sure to check the\n",
      "copyright laws for your country before downloading or redistributing\n",
      "this or any other Project Gutenberg eBook.\n",
      "\n",
      "This header should be the first thing seen when viewing this Project\n",
      "Gutenberg file.  Please do not remove it.  Do not change or edit the\n",
      "header without written permission.\n",
      "\n",
      "Please read the \"legal small print,\" and other information about the\n",
      "eBook and Project Gutenberg at the bottom of this file.  Included is\n",
      "important information about your specific rights and restrictions in\n",
      "how the file may be used.  You can also find out about how to make a\n",
      "donation to Project Gutenberg, and how to get involved.\n",
      "\n",
      "\n",
      "**Welcome To The World of Free Plain Vanilla Electronic Texts**\n",
      "\n",
      "**EBooks Readable By Both Humans and By Computers, Since 1971**\n",
      "\n",
      "*****These EBooks Were Prepared By Thousands of Volunteers*****\n",
      "\n",
      "\n",
      "\n",
      "Title: Quo Vadis A Narrative of the Time of Nero\n",
      "\n",
      "Auth\n"
     ]
    }
   ],
   "source": [
    "print('len of text: {}'.format(len(text)))\n",
    "print(text[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5c45a02-68e2-4a4a-b5ff-e92a1ba3eead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '#', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\x8c', '\\x9c', 'Æ', 'æ', 'ç', 'é', 'ë', 'ô']\n",
      "vocabulary length: 86\n"
     ]
    }
   ],
   "source": [
    "#get all unique charaters that occure in text\n",
    "chars = sorted(list(set(text)))\n",
    "print(chars)\n",
    "vocab_size = len(chars)\n",
    "print(\"vocabulary length: {}\".format(len(chars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0350a436-864d-4547-b48f-8b1c3206a581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [68, 72, 66, 1, 73, 52, 55, 60, 70, 1, 55, 66, 64, 60, 65, 56]\n",
      "Decoded: quo vadis domine\n"
     ]
    }
   ],
   "source": [
    "# transform characters to numeric data\n",
    "strToInt = {ch:i for i,ch in enumerate(chars)}\n",
    "intToStr = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s:[strToInt[c] for c in s] #encode string to integers\n",
    "decode = lambda l:''.join([intToStr[i] for i in l]) #decode intigers to string\n",
    "\n",
    "encoded = encode('quo vadis domine')\n",
    "print('Encoded:', encoded)\n",
    "print('Decoded:', decode(encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "660dc71a-e04f-440e-9b7e-060e03b09511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([630169]) torch.int64\n",
      "tensor([39, 69, 66, 61, 56, 54, 71,  1, 30, 72, 71, 56, 65, 53, 56, 69, 58,  1,\n",
      "        28, 25, 66, 66, 62,  9,  1, 40, 72, 66,  1, 45, 52, 55, 60, 70,  9,  1,\n",
      "        53, 76,  1, 31, 56, 65, 69, 76, 62,  1, 42, 60, 56, 65, 62, 60, 56, 74,\n",
      "        60, 54, 77,  0,  0, 26, 66, 67, 76, 69, 60, 58, 59, 71,  1, 63, 52, 74,\n",
      "        70,  1, 52, 69, 56,  1, 54, 59, 52, 65, 58, 60, 65, 58,  1, 52, 63, 63,\n",
      "         1, 66, 73, 56, 69,  1, 71, 59, 56,  1, 74, 66, 69, 63, 55, 11,  1, 25,\n",
      "        56,  1, 70, 72, 69, 56,  1, 71, 66,  1, 54, 59, 56, 54, 62,  1, 71, 59,\n",
      "        56,  0, 54, 66, 67, 76, 69, 60, 58, 59, 71,  1, 63, 52, 74, 70,  1, 57,\n",
      "        66, 69,  1, 76, 66, 72, 69,  1, 54, 66, 72, 65, 71, 69, 76,  1, 53, 56,\n",
      "        57, 66, 69, 56,  1, 55, 66, 74, 65, 63, 66, 52, 55, 60, 65, 58,  1, 66,\n",
      "        69,  1, 69, 56, 55, 60, 70, 71, 69, 60, 53, 72, 71, 60, 65, 58,  0, 71,\n",
      "        59, 60, 70,  1, 66, 69,  1, 52, 65, 76,  1, 66, 71, 59, 56, 69,  1, 39,\n",
      "        69, 66, 61, 56, 54, 71,  1, 30, 72, 71, 56, 65, 53, 56, 69, 58,  1, 56,\n",
      "        25, 66, 66, 62, 11,  0,  0, 43, 59, 60, 70,  1, 59, 56, 52, 55, 56, 69,\n",
      "         1, 70, 59, 66, 72, 63, 55,  1, 53, 56,  1, 71, 59, 56,  1, 57, 60, 69,\n",
      "        70, 71,  1, 71, 59, 60, 65, 58,  1, 70, 56, 56, 65,  1, 74, 59, 56, 65,\n",
      "         1, 73, 60, 56, 74, 60, 65, 58,  1, 71, 59, 60, 70,  1, 39, 69, 66, 61,\n",
      "        56, 54, 71,  0, 30, 72, 71, 56, 65, 53, 56, 69, 58,  1, 57, 60, 63, 56,\n",
      "        11,  1,  1, 39, 63, 56, 52, 70, 56,  1, 55, 66,  1, 65, 66, 71,  1, 69,\n",
      "        56, 64, 66, 73, 56,  1, 60, 71, 11,  1,  1, 27, 66,  1, 65, 66, 71,  1,\n",
      "        54, 59, 52, 65, 58, 56,  1, 66, 69,  1, 56, 55, 60, 71,  1, 71, 59, 56,\n",
      "         0, 59, 56, 52, 55, 56, 69,  1, 74, 60, 71, 59, 66, 72, 71,  1, 74, 69,\n",
      "        60, 71, 71, 56, 65,  1, 67, 56, 69, 64, 60, 70, 70, 60, 66, 65, 11,  0,\n",
      "         0, 39, 63, 56, 52, 70, 56,  1, 69, 56, 52, 55,  1, 71, 59, 56,  1,  3,\n",
      "        63, 56, 58, 52, 63,  1, 70, 64, 52, 63, 63,  1, 67, 69, 60, 65, 71,  9,\n",
      "         3,  1, 52, 65, 55,  1, 66, 71, 59, 56, 69,  1, 60, 65, 57, 66, 69, 64,\n",
      "        52, 71, 60, 66, 65,  1, 52, 53, 66, 72, 71,  1, 71, 59, 56,  0, 56, 25,\n",
      "        66, 66, 62,  1, 52, 65, 55,  1, 39, 69, 66, 61, 56, 54, 71,  1, 30, 72,\n",
      "        71, 56, 65, 53, 56, 69, 58,  1, 52, 71,  1, 71, 59, 56,  1, 53, 66, 71,\n",
      "        71, 66, 64,  1, 66, 57,  1, 71, 59, 60, 70,  1, 57, 60, 63, 56, 11,  1,\n",
      "         1, 32, 65, 54, 63, 72, 55, 56, 55,  1, 60, 70,  0, 60, 64, 67, 66, 69,\n",
      "        71, 52, 65, 71,  1, 60, 65, 57, 66, 69, 64, 52, 71, 60, 66, 65,  1, 52,\n",
      "        53, 66, 72, 71,  1, 76, 66, 72, 69,  1, 70, 67, 56, 54, 60, 57, 60, 54,\n",
      "         1, 69, 60, 58, 59, 71, 70,  1, 52, 65, 55,  1, 69, 56, 70, 71, 69, 60,\n",
      "        54, 71, 60, 66, 65, 70,  1, 60, 65,  0, 59, 66, 74,  1, 71, 59, 56,  1,\n",
      "        57, 60, 63, 56,  1, 64, 52, 76,  1, 53, 56,  1, 72, 70, 56, 55, 11,  1,\n",
      "         1, 48, 66, 72,  1, 54, 52, 65,  1, 52, 63, 70, 66,  1, 57, 60, 65, 55,\n",
      "         1, 66, 72, 71,  1, 52, 53, 66, 72, 71,  1, 59, 66, 74,  1, 71, 66,  1,\n",
      "        64, 52, 62, 56,  1, 52,  0, 55, 66, 65, 52, 71, 60, 66, 65,  1, 71, 66,\n",
      "         1, 39, 69, 66, 61, 56, 54, 71,  1, 30, 72, 71, 56, 65, 53, 56, 69, 58,\n",
      "         9,  1, 52, 65, 55,  1, 59, 66, 74,  1, 71, 66,  1, 58, 56, 71,  1, 60,\n",
      "        65, 73, 66, 63, 73, 56, 55, 11,  0,  0,  0,  8,  8, 46, 56, 63, 54, 66,\n",
      "        64, 56,  1, 43, 66,  1, 43, 59, 56,  1, 46, 66, 69, 63, 55,  1, 66, 57,\n",
      "         1, 29, 69, 56, 56,  1, 39, 63, 52, 60, 65,  1, 45, 52, 65, 60, 63, 63,\n",
      "        52,  1, 28, 63, 56, 54, 71, 69, 66, 65, 60, 54,  1, 43, 56, 75, 71, 70,\n",
      "         8,  8,  0,  0,  8,  8, 28, 25, 66, 66, 62, 70,  1, 41, 56, 52, 55, 52,\n",
      "        53, 63, 56,  1, 25, 76,  1, 25, 66, 71, 59,  1, 31, 72, 64, 52, 65, 70,\n",
      "         1, 52, 65, 55,  1, 25, 76,  1, 26, 66, 64, 67, 72, 71, 56, 69, 70,  9,\n",
      "         1, 42, 60, 65, 54, 56,  1, 13, 20, 18, 13,  8,  8,  0,  0,  8,  8,  8,\n",
      "         8,  8, 43, 59, 56, 70, 56,  1, 28, 25, 66, 66, 62, 70,  1, 46, 56, 69,\n",
      "        56,  1, 39, 69, 56, 67, 52, 69, 56, 55,  1, 25, 76,  1, 43, 59, 66, 72,\n",
      "        70, 52, 65, 55, 70,  1, 66, 57,  1, 45, 66, 63, 72, 65, 71, 56, 56, 69,\n",
      "        70,  8,  8,  8,  8,  8,  0,  0,  0,  0, 43, 60, 71, 63, 56, 21,  1, 40,\n",
      "        72, 66,  1, 45, 52, 55, 60, 70,  1, 24,  1, 37, 52, 69, 69, 52, 71, 60,\n",
      "        73, 56,  1, 66, 57,  1, 71, 59, 56,  1, 43, 60, 64, 56,  1, 66, 57,  1,\n",
      "        37, 56, 69, 66,  0,  0, 24, 72, 71, 59])\n"
     ]
    }
   ],
   "source": [
    "#encoding entire \"quo vadis\" text\n",
    "import torch #PyTorch lib is used for building transformer components https://pytorch.org\n",
    "data = torch.tensor(encode(text), dtype=torch.long) #encode whole text\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad10e156-9de1-4613-8cf7-444e3ed09f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and validation sets\n",
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecdbf70d-05fc-415c-b60b-2a3e27dc1140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([39, 69, 66, 61, 56, 54, 71,  1, 30])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bda614e2-8f4f-43aa-9e76-4fc4929a07b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([39]) the target: 69\n",
      "when input is tensor([39, 69]) the target: 66\n",
      "when input is tensor([39, 69, 66]) the target: 61\n",
      "when input is tensor([39, 69, 66, 61]) the target: 56\n",
      "when input is tensor([39, 69, 66, 61, 56]) the target: 54\n",
      "when input is tensor([39, 69, 66, 61, 56, 54]) the target: 71\n",
      "when input is tensor([39, 69, 66, 61, 56, 54, 71]) the target: 1\n",
      "when input is tensor([39, 69, 66, 61, 56, 54, 71,  1]) the target: 30\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5438617b-3a44-4f7a-af11-32da4c154266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 1, 81, 58, 60, 70,  1, 66, 57],\n",
      "        [58, 66,  0, 53, 56, 76, 66, 65],\n",
      "        [60, 70,  1, 52, 69, 64,  9,  0],\n",
      "        [64, 52, 60, 55, 56, 65, 70,  1]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[81, 58, 60, 70,  1, 66, 57,  1],\n",
      "        [66,  0, 53, 56, 76, 66, 65, 55],\n",
      "        [70,  1, 52, 69, 64,  9,  0, 52],\n",
      "        [52, 60, 55, 56, 65, 70,  1, 60]])\n",
      "----\n",
      "when input is [1] the target: 81\n",
      "when input is [1, 81] the target: 58\n",
      "when input is [1, 81, 58] the target: 60\n",
      "when input is [1, 81, 58, 60] the target: 70\n",
      "when input is [1, 81, 58, 60, 70] the target: 1\n",
      "when input is [1, 81, 58, 60, 70, 1] the target: 66\n",
      "when input is [1, 81, 58, 60, 70, 1, 66] the target: 57\n",
      "when input is [1, 81, 58, 60, 70, 1, 66, 57] the target: 1\n",
      "when input is [58] the target: 66\n",
      "when input is [58, 66] the target: 0\n",
      "when input is [58, 66, 0] the target: 53\n",
      "when input is [58, 66, 0, 53] the target: 56\n",
      "when input is [58, 66, 0, 53, 56] the target: 76\n",
      "when input is [58, 66, 0, 53, 56, 76] the target: 66\n",
      "when input is [58, 66, 0, 53, 56, 76, 66] the target: 65\n",
      "when input is [58, 66, 0, 53, 56, 76, 66, 65] the target: 55\n",
      "when input is [60] the target: 70\n",
      "when input is [60, 70] the target: 1\n",
      "when input is [60, 70, 1] the target: 52\n",
      "when input is [60, 70, 1, 52] the target: 69\n",
      "when input is [60, 70, 1, 52, 69] the target: 64\n",
      "when input is [60, 70, 1, 52, 69, 64] the target: 9\n",
      "when input is [60, 70, 1, 52, 69, 64, 9] the target: 0\n",
      "when input is [60, 70, 1, 52, 69, 64, 9, 0] the target: 52\n",
      "when input is [64] the target: 52\n",
      "when input is [64, 52] the target: 60\n",
      "when input is [64, 52, 60] the target: 55\n",
      "when input is [64, 52, 60, 55] the target: 56\n",
      "when input is [64, 52, 60, 55, 56] the target: 65\n",
      "when input is [64, 52, 60, 55, 56, 65] the target: 70\n",
      "when input is [64, 52, 60, 55, 56, 65, 70] the target: 1\n",
      "when input is [64, 52, 60, 55, 56, 65, 70, 1] the target: 60\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2527)\n",
    "batch_size = 4 # number of independant sequences processed in parallel\n",
    "block_size = 8 # maximum context length of predictions\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate batch of data of input x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): #batch dimension\n",
    "    for t in range(block_size): #time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f'when input is {context.tolist()} the target: {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f39aca5-95d0-4add-b35f-66fa437ff141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 86])\n",
      "tensor(4.8234, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "JK5kéDU!7ë ô*6wQ)8frZÆ9oBhzdZ?]1:mZxAsb1l tor.RX (8rj6O;ç8ÆTPAb);HIôIU:;*]wFRt-jU6tdYzô5,yP-*ëFH\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(2334)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets = None):\n",
    "        #idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) #(B,T,C)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "        \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        #idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus on last time step\n",
    "            logits = logits[:, -1, :] #becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=1) # (B, C)\n",
    "            # samble from distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) #(B, T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18479762-52b4-4fe0-b2bb-6baf10a687fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7111ca12-9855-4124-886f-bb8be4fe2980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3486311435699463\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    #sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ac237ac-b6d9-457b-ab5a-413ede00fecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "veces. jondiriu, ce ps, th oure a are[pe; t, m t il mbe ws thickndeth s wad\n",
      "uert ctherewasanthe, g Afelveng foxcethiri! if The po he icaty ha[M12Ly.  te whed t isthiste ncked n t d tiang  asthigerey irnd to Ahd ha d d(, f has o her gim tulereg towhais wong t, tk; or e;\n",
      "\" atmROtununazedearinthorouessseroinchewofugas ns Thyok?\"\n",
      "stheto had ad wium, wad, theppinqus ia wr wowo t bl m. iushe  hineribus\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=400)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58a20c18-d6e2-4c95-8ea3-da6521ef61ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "B,T,C = 4,8,2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cc7bf06-aff4-4ff4-9df4-da10abe15f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x[b,t] = mean_{i<=t} x[b,i]\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] #t,C\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44abe7df-4524-4145-a81e-a882ee7c05cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x #(B, T, T) @ (B, T, C) ---> (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19ca5f0a-94c5-4a85-a2f8-099820bbc06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1117, -0.4966],\n",
       "        [ 0.1631, -0.8817],\n",
       "        [ 0.0539,  0.6684],\n",
       "        [-0.0597, -0.4675],\n",
       "        [-0.2153,  0.8840],\n",
       "        [-0.7584, -0.3689],\n",
       "        [-0.3424, -1.4020],\n",
       "        [ 0.3206, -1.0219]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15dc8f18-f10b-4593-8513-da09d75e12c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1117, -0.4966],\n",
       "        [ 0.0257, -0.6891],\n",
       "        [ 0.0351, -0.2366],\n",
       "        [ 0.0114, -0.2944],\n",
       "        [-0.0339, -0.0587],\n",
       "        [-0.1547, -0.1104],\n",
       "        [-0.1815, -0.2949],\n",
       "        [-0.1187, -0.3858]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bb0eede-38a9-409e-a23a-e08619cc63fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e35f4d4-3b83-4331-b808-d5a644b16d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=tensor([[1., 6.],\n",
      "        [6., 7.],\n",
      "        [0., 2.]])\n",
      "--\n",
      "c=tensor([[1.0000, 6.0000],\n",
      "        [3.5000, 6.5000],\n",
      "        [2.3333, 5.0000]])\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(23)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print(f'a={a}')\n",
    "print('--')\n",
    "print(f'b={b}')\n",
    "print('--')\n",
    "print(f'c={c}')\n",
    "print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4423b24b-54d1-4843-a82c-5c3de37c07db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
